params {
    config_profile_description = 'Biowulf nf-core config'
    config_profile_contact     = 'staff@hpc.nih.gov'
    config_profile_url         = 'https://hpc.nih.gov/apps/nextflow.html'
    igenomes_base              = '/fdb/igenomes_nf/'
}

executor {

    name              = 'slurm'
    queue             = 'norm'
    queueSize         = 200
    pollInterval      = '2 min'
    queueStatInterval = '5 min'
    submitRateLimit   = '6/1min'

}

// Preform work directory cleanup after a successful run
cleanup          = true

timeline.enabled = true
report.enabled   = true

singularity {
    enabled      = true
    autoMounts   = true
    cacheDir     = "/data/${USER}/nxf_singularity_cache"
    libraryDir   = "/fdb/nxf/singularity-images"
    envWhitelist = 'https_proxy,http_proxy,ftp_proxy,DISPLAY,SLURM_JOBID,SINGULARITY_BINDPATH'
}

env {
    SINGULARITY_CACHEDIR = "/data/$USER/.singularity"
    PYTHONNOUSERSITE     = 1
    OMP_NUM_THREADS      = 1
    OPENBLAS_NUM_THREADS = 1
}


process {

    executor       = 'slurm'
    maxRetries     = 2
    resourceLimits = [ cpus: 192, memory: 751.GB, time: 240.h ]
    clusterOptions = ' --gres=lscratch:200 '

    scratch        = '/lscratch/$SLURM_JOB_ID'

    stageInMode    = 'symlink'
    stageOutMode   = 'rsync'

    // for running pipeline on group sharing data directory, this can avoid inconsistent files timestamps
    cache          = 'lenient'

}
