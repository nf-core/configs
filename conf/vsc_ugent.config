// Set parameters to ignore for validation
validation {
    ignoreParams = [
        'vsc_ugent_hostname',
        'vsc_ugent_tier1_project',
        'vsc_ugent_scratchdir',
        'vsc_ugent_cluster',
        'vsc_ugent_timestamp'
    ]
}

// Get the hostname and check some values for tier1
params.vsc_ugent_hostname = {
    try {
        return ['/bin/bash', '-c', 'sinfo --local -N -h | head -n 1 | cut -d " " -f1'].execute().text.trim()
    } catch (e) {
        System.err.println("WARNING: Could not run sinfo to determine current cluster, defaulting to doduo: ${e.message}")
        return "doduo"
    }
}.call()

params.vsc_ugent_tier1_project = System.getenv("SBATCH_ACCOUNT") ?: System.getenv("SLURM_ACCOUNT")

includeConfig ({
    if (! params.vsc_ugent_tier1_project && params.vsc_ugent_hostname.contains("dodrio")) {
        // Hard-code that Tier 1 cluster dodrio requires a project account
        System.err.println("Please specify your VSC project account with environment variable SBATCH_ACCOUNT or SLURM_ACCOUNT.")
        System.exit(1)
    }
}.call())


// Define the Scratch directory
params.vsc_ugent_scratchdir =   System.getenv("VSC_SCRATCH_PROJECTS_BASE") ? "${System.getenv("VSC_SCRATCH_PROJECTS_BASE")}/${params.vsc_ugent_tier1_project}" : // Tier 1 scratch
                    System.getenv("VSC_SCRATCH_VO_USER") ?: // VO scratch
                    System.getenv("VSC_SCRATCH") // user scratch

// Specify the work directory
workDir = "${params.vsc_ugent_scratchdir}/work"

// Perform work directory cleanup when the run has succesfully completed
cleanup = true

// Reduce the job submit rate to about 30 per minute, this way the server won't be bombarded with jobs
// Limit queueSize to keep job rate under control and avoid timeouts
// Extend the exit read timeout to 3 days to avoid timeouts on tier1 clusters
executor {
    submitRateLimit = '30/1min'
    queueSize = 100
    exitReadTimeout = "3day"
}

// Add backoff strategy to catch cluster timeouts and proper symlinks of files in scratch to the work directory
process {
    stageInMode = "symlink"
    stageOutMode = "rsync"
    errorStrategy = { sleep(Math.pow(2, task.attempt ?: 1) * 200 as long); return 'retry' }
    maxRetries    = 5
    // add GPU support with GPU label
    // Adapted from https://github.com/nf-core/configs/blob/76970da5d4d7eadd8354ef5c5af2758ce187d6bc/conf/leicester.config#L26
    // More info on GPU SLURM options: https://hpc.vub.be/docs/job-submission/gpu-job-types/#gpu-job-types
    withLabel: use_gpu {
        // works on all GPU clusters of Tier 1 and Tier 2
        beforeScript = 'module load cuDNN/8.4.1.50-CUDA-11.7.0'
        // TODO: Support multi-GPU configuations with e.g. ${task.ext.gpus}
        // only add account if present
        clusterOptions = {"--gpus=1" + (params.vsc_ugent_tier1_project ? " --account=${params.vsc_ugent_tier1_project}" : "")}
        containerOptions = {
                // Ensure that the container has access to the GPU
                workflow.containerEngine == "singularity" ? '--nv':
                ( workflow.containerEngine == "docker" ? '--gpus all': null )
            }
    }
}

// Specify that singularity should be used and where the cache dir will be for the images
// containerOptions --containall or --no-home can break e.g. downloading big models to ~/.cache
// solutions to error 'no disk space left':
//   1. remove --no-home using NXF_APPTAINER_HOME_MOUNT=true
//   2. increase the memory of the job.
//   3. change the script so the tool does not use the home folder.
//   4. increasing the Singularity memory limit using --memory.
singularity {
    enabled = true
    autoMounts = true
    cacheDir = "${params.vsc_ugent_scratchdir}/singularity"
}

env {
    APPTAINER_TMPDIR="${params.vsc_ugent_scratchdir}/.apptainer/tmp"
    APPTAINER_CACHEDIR="${params.vsc_ugent_scratchdir}/.apptainer/cache"
}

// AWS maximum retries for errors (This way the pipeline doesn't fail if the download fails one time)
aws.client.maxErrorRetry = 3

params.vsc_ugent_cluster = System.getenv("HPCUGENT_FAMILY_CLUSTER_VERSION") ?: System.getenv("SLURM_CLUSTERS") ?: ""

includeConfig ({
    if( !params.vsc_ugent_cluster ) {
        System.err.println("WARNING: Could not get the name of the currently used cluster, defaulting to doduo")
        params.vsc_ugent_cluster = "doduo"
    }
}.call())

params.config_profile_description = 'Configuration profile for execution of Nextflow pipelines on the VSC UGhent HPC.'
params.config_profile_contact = 'ict@cmgg.be'
params.config_profile_url = 'https://www.ugent.be/hpc/en'

params.vsc_ugent_timestamp = params.containsKey('trace_report_suffix') ? params.trace_report_suffix : new java.util.Date().format('yyyy-MM-dd_HH-mm-ss')

co2footprint {
    traceFile = "${params.get('outdir', "$launchDir")}/pipeline_info/co2footprint_trace_${params.vsc_ugent_timestamp}.txt"
    summaryFile = "${params.get('outdir', "$launchDir")}/pipeline_info/co2footprint_summary_${params.vsc_ugent_timestamp}.txt"
    reportFile = "${params.get('outdir', "$launchDir")}/pipeline_info/co2footprint_report_${params.vsc_ugent_timestamp}.html"
    location = 'BE'
//emApiKey = secrets.EM_API_KEY               // set your API key as Nextflow secret with the name 'EM_API_KEY'
    pue = 1.33                                   // replace with PUE of your data center
    machineType = 'compute cluster'             // set to 'compute cluster', 'local', or 'cloud'
}

params.max_memory = params.vsc_ugent_cluster == 'doduo' ? 250.GB :
    params.vsc_ugent_cluster == "shinx" ? 360.GB :
    params.vsc_ugent_cluster == "gallade" ? 940.GB :
    params.vsc_ugent_cluster == "joltik" ? 256.GB :
    params.vsc_ugent_cluster == "accelgor" ? 500.GB :
    params.vsc_ugent_cluster == "litleo" ? 315.GB :
    params.vsc_ugent_cluster == "donphan" ? 27.GB :
    params.vsc_ugent_cluster == "cpu_rome" ? 256.GB :
    params.vsc_ugent_cluster == "cpu_rome_512" ? 512.GB :
    params.vsc_ugent_cluster == "cpu_milan" ? 256.GB :
    params.vsc_ugent_cluster == "gpu_rome_a100_40" ? 256.GB :
    params.vsc_ugent_cluster == "gpu_rome_a100_80" ? 512.GB :
    params.vsc_ugent_cluster == "debug_rome" ? 256.GB :
    params.vsc_ugent_cluster == "cpu_rome_all" ? 250.GB :
    params.vsc_ugent_cluster == "gpu_rome_a100" ? 384.GB :
    250.GB

params.max_cpus = params.vsc_ugent_cluster == 'doduo' ? 96 :
    params.vsc_ugent_cluster == "shinx" ? 192 :
    params.vsc_ugent_cluster == "gallade" ? 128 :
    params.vsc_ugent_cluster == "joltik" ? 32 :
    params.vsc_ugent_cluster == "accelgor" ? 48 :
    params.vsc_ugent_cluster == "litleo" ? 48 :
    params.vsc_ugent_cluster == "donphan" ? 8 :
    params.vsc_ugent_cluster == "cpu_rome" ? 128 :
    params.vsc_ugent_cluster == "cpu_rome_512" ? 128 :
    params.vsc_ugent_cluster == "cpu_milan" ? 128 :
    params.vsc_ugent_cluster == "gpu_rome_a100_40" ? 48 :
    params.vsc_ugent_cluster == "gpu_rome_a100_80" ? 48 :
    params.vsc_ugent_cluster == "debug_rome" ? 48 :
    params.vsc_ugent_cluster == "cpu_rome_all" ? 128 :
    params.vsc_ugent_cluster == "gpu_rome_a100" ? 48 :
    96

params.max_time = "71hours59minutes"

process.executor = 'slurm'
process.queue = {
    params.tier1_project ? "dodrio/${params.vsc_ugent_cluster}" : params.vsc_ugent_cluster
}
process.resourceLimits = [
    cpus: params.max_cpus,
    memory: params.max_memory,
    time: params.max_time
]
