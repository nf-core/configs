// Define the Scratch directory
def scratch_dir = System.getenv("VSC_SCRATCH") ?: "scratch/"

// Specify the work directory
workDir = "$scratch_dir/work"

// Perform work directory cleanup when the run has succesfully completed
cleanup = true

// Reduce the job submit rate to about 30 per minute, this way the server won't be bombarded with jobs
// Limit queueSize to keep job rate under control and avoid timeouts
executor {
    submitRateLimit = '30/1min'
    queueSize = 10
}

// Add backoff strategy to catch cluster timeouts and proper symlinks of files in scratch to the work directory
process {
    stageInMode = "symlink"
    stageOutMode = "rsync"
    errorStrategy = { sleep(Math.pow(2, task.attempt) * 200 as long); return 'retry' }
    maxRetries    = 5
}

// Specify that singularity should be used and where the cache dir will be for the images
singularity {
    enabled = true
    autoMounts = true
    cacheDir = "$scratch_dir/.singularity"
}

env {
    SINGULARITY_CACHEDIR="$scratch_dir/.singularity"
    APPTAINER_CACHEDIR="$scratch_dir/.apptainer"
}

// AWS maximum retries for errors (This way the pipeline doesn't fail if the download fails one time)
aws {
        maxErrorRetry = 3
}

// Define profiles for each cluster
profiles {
    genius {
        params {
            config_profile_description = 'HPC_GENIUS profile for use on the genius cluster of the VSC HPC.'
            config_profile_contact = 'joon.klaps@kuleuven.be'
            config_profile_url = 'https://docs.vscentrum.be/en/latest/index.html'
            max_memory = 703.GB  // 768 - 65 so 65GB for overhead, max is 720000MB
            max_time = 168.h
            max_cpus = 36
        }

        process {
            executor = 'slurm'
            queue = {
                switch (task.memory) {
                case { it >=  175.GB }: // max is 180000
                    switch (task.time) {
                    case { it >= 72.h }:
                        return 'dedicated_big_bigmem'
                    default:
                        return 'bigmem'
                    }
                default:
                    switch (task.time) {
                    case { it >= 72.h }:
                        return 'batch_long'
                    default:
                        return 'batch'
                    }
                }
            }
            clusterOptions = { "--cluster genius --account=${params.project}" }
            scratch = "$scratch_dir"
        }
    }

    wice {
        params {
            config_profile_description = 'HPC_WICE profile for use on the Wice cluster of the VSC HPC.'
            config_profile_contact = 'joon.klaps@kuleuven.be'
            config_profile_url = 'https://docs.vscentrum.be/en/latest/index.html'
            max_memory = 1968.GB // max is 2016000
            max_cpus = 72
            max_time = 168.h
        }

        process {
            executor = 'slurm'
            queue = {
                switch (task.memory) {
                case { it >=  239.GB }:  // max is 244800
                    switch (task.time) {
                    case { it >= 72.h }:
                        return 'dedicated_big_bigmem'
                    default:
                        return 'bigmem'
                    }
                default:
                    switch (task.time) {
                    case { it >= 72.h }:
                        return 'batch_long'
                    default:
                        return 'batch'
                    }
                }
            }
            clusterOptions = { "--cluster wice --account=${params.project}" }
            scratch = "$scratch_dir"
        }
    }

    superdome {
        params {
            config_profile_description = 'HPC_SUPERDOME profile for use on the genius cluster of the VSC HPC.'
            config_profile_contact = 'joon.klaps@kuleuven.be'
            config_profile_url = 'https://docs.vscentrum.be/en/latest/index.html'
            max_memory = 5772.GB // 6000 - 228 so 228GB for overhead, max is 5910888MB
            max_cpus = 14
            max_time = 168.h
        }

        process {
            executor = 'slurm'
            queue = { task.time <= 72.h ? 'superdome' : 'superdome_long' }
            clusterOptions = { "--cluster genius --account=${params.project}" }
            scratch = "$scratch_dir"
        }
    }
}
