// UPPMAX Config Profile
params {
  // Description is overwritten for other clusters below
  config_profile_description = 'UPPMAX (Bianca) cluster profile provided by nf-core/configs.'
  config_profile_contact = 'Phil Ewels (@ewels)'
  config_profile_url = 'https://www.uppmax.uu.se/'
  project = null
  clusterOptions = null
  schema_ignore_params = "genomes,input_paths,cluster-options,clusterOptions,project"
  validationSchemaIgnoreParams = "genomes,input_paths,cluster-options,clusterOptions,project,schema_ignore_params"
  save_reference = true
  // Defaults set for Bianca - other clusters set below
  max_memory = 500.GB
  max_cpus = 16
  max_time = 240.h
  // illumina iGenomes reference file paths on UPPMAX
  igenomes_base = '/sw/data/igenomes/'
}

singularity {
  enabled = true
  envWhitelist = 'SNIC_TMP'
}

def hostname = "r1"
try {
    hostname = ['/bin/bash', '-c', 'sinfo --local -N -h | grep -m 1 -F -v CLUSTER: | cut -f1 -d" "'].execute().text.trim()
} catch (java.io.IOException e) {
    System.err.println("WARNING: Could not run sinfo to determine current cluster, defaulting to rackham")
}

// closure to create a suitable clusterOptions
def clusterOptionsCreator = { m ->
    String base = "-A $params.project ${params.clusterOptions ?: ''}"
    // Do not use -p node on irma or if a thin node/core is enough
    if (m <= 125.GB || hostname.startsWith("i")) {
        return base
    }

    // cluster is miarka
    if (hostname.startsWith("m")) {
        // job will fit on a regular node
        if (m <= 357.GB) {
            return base
        }
        // job requires at least a 2TB node
        if (m <= 2000.GB) {
            return base + " --mem 2TB "
        }
        // job requires the largest node
        return base + " -C mem4TB "
    }

    if (m <= 250.GB) {
        return base + " -p node -C mem256GB "
    }


    // Use mem1TB for remaining cases on rackham (no 512 Gbyte nodes)
    if (hostname.startsWith("r")) {
        return base + " -p node -C mem1TB "
    }

    if (m > 500.GB) {
       // Special case for snowy very fat node (only remaining case that's above 500 GB)
       return base + " -p veryfat "
    }

    // Should only be cases for mem512GB left (snowy and bianca)
    return base + " -p node -C mem512GB "
}

process {
  executor = 'slurm'
  clusterOptions = { clusterOptionsCreator(task.memory) }
  // Use node local storage for execution.
  scratch = '$SNIC_TMP'
}

// Cluster: Snowy
//   Caution: Bianca nodes will be project name-nodenumber, e.g. sens2021500-001
//   so cannot rely on just starting with 's'
if (hostname.matches("^s[0-9][0-9]*")) {
  params.max_time = 700.h
  params.max_memory = 3880.GB
  params.config_profile_description = 'UPPMAX (Snowy) cluster profile provided by nf-core/configs.'
}

// Cluster: Irma
if (hostname.startsWith("i")) {
  params.max_memory = 250.GB
  params.config_profile_description = 'UPPMAX (Irma) cluster profile provided by nf-core/configs.'
}

// Cluster: Miarka
if (hostname.startsWith("m")) {
  params.max_memory = 357.GB
  params.max_cpus = 48
  params.max_time = 480.h
  params.config_profile_description = 'UPPMAX (Miarka) cluster profile provided by nf-core/configs.'
}

// Cluster: Rackham
if (hostname.startsWith("r")) {
  params.max_cpus = 20
  params.max_memory = 970.GB
  params.config_profile_description = 'UPPMAX (Rackham) cluster profile provided by nf-core/configs.'
}

// Cluster: Bianca - set in initial params block above

// Additional devel profile for running in devel queue
// Run with `-profile upppmax,devel`
profiles {
  devel {
    params {
      config_profile_description = 'Testing & development profile for UPPMAX, provided by nf-core/configs.'
      // Max resources to be requested by a devel job
      max_memory = 120.GB
      max_time = 1.h
    }
    executor.queueSize = 1
    process.queue = 'devel'
  }
}
