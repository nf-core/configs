// Get the hostname and check some values for tier1
def hostname = "doduo"
try {
    hostname = ['/bin/bash', '-c', 'sinfo --local -N -h | head -n 1 | cut -d " " -f1'].execute().text.trim()
} catch (java.io.IOException e) {
    System.err.println("WARNING: Could not run sinfo to determine current cluster, defaulting to doduo")
}

def tier1_project = System.getenv("SBATCH_ACCOUNT") ?: System.getenv("SLURM_ACCOUNT")

if (! tier1_project && hostname.contains("dodrio")) {
    // Hard-code that Tier 1 cluster dodrio requires a project account
    System.err.println("Please specify your VSC project account with environment variable SBATCH_ACCOUNT or SLURM_ACCOUNT.")
    System.exit(1)
}

// Define the Scratch directory
def scratch_dir =   System.getenv("VSC_SCRATCH_PROJECTS_BASE") ? "${System.getenv("VSC_SCRATCH_PROJECTS_BASE")}/$tier1_project" : // Tier 1 scratch
                    System.getenv("VSC_SCRATCH_VO_USER") ?: // VO scratch
                    System.getenv("VSC_SCRATCH") // user scratch

// Specify the work directory
workDir = "$scratch_dir/work"

// Perform work directory cleanup when the run has succesfully completed
cleanup = true

// Reduce the job submit rate to about 30 per minute, this way the server won't be bombarded with jobs
// Limit queueSize to keep job rate under control and avoid timeouts
// Extend the exit read timeout to 3 days to avoid timeouts on tier1 clusters
executor {
    submitRateLimit = '30/1min'
    queueSize = 100
    exitReadTimeout = "3day"
}

// Add backoff strategy to catch cluster timeouts and proper symlinks of files in scratch to the work directory
process {
    stageInMode = "symlink"
    stageOutMode = "rsync"
    errorStrategy = { sleep(Math.pow(2, task.attempt ?: 1) * 200 as long); return 'retry' }
    maxRetries    = 5
    // add GPU support with GPU label
    // Adapted from https://github.com/nf-core/configs/blob/76970da5d4d7eadd8354ef5c5af2758ce187d6bc/conf/leicester.config#L26
    // More info on GPU SLURM options: https://hpc.vub.be/docs/job-submission/gpu-job-types/#gpu-job-types
    withLabel: use_gpu {
        // works on all GPU clusters of Tier 1 and Tier 2
        beforeScript = 'module load cuDNN/8.4.1.50-CUDA-11.7.0'
        // TODO: Support multi-GPU configuations with e.g. ${task.ext.gpus}
        // only add account if present
        clusterOptions = {"--gpus=1" + (tier1_project ? " --account=$tier1_project" : "")}
        containerOptions = {
                // Ensure that the container has access to the GPU
                workflow.containerEngine == "singularity" ? '--nv':
                ( workflow.containerEngine == "docker" ? '--gpus all': null )
            }
    }
}

// Specify that singularity should be used and where the cache dir will be for the images
// containerOptions --containall or --no-home can break e.g. downloading big models to ~/.cache
// solutions to error 'no disk space left':
//   1. remove --no-home using NXF_APPTAINER_HOME_MOUNT=true
//   2. increase the memory of the job.
//   3. change the script so the tool does not use the home folder.
//   4. increasing the Singularity memory limit using --memory.
singularity {
    enabled = true
    autoMounts = true
    cacheDir = "$scratch_dir/singularity"
}

env {
    APPTAINER_TMPDIR="$scratch_dir/.apptainer/tmp"
    APPTAINER_CACHEDIR="$scratch_dir/.apptainer/cache"
}

// AWS maximum retries for errors (This way the pipeline doesn't fail if the download fails one time)
aws {
    maxErrorRetry = 3
}

def cluster = System.getenv("SLURM_CLUSTERS") ?: System.getenv("HPCUGENT_FAMILY_CLUSTER_VERSION") ?: ""

if( !cluster ) {
    System.err.println("WARNING: Could not get the name of the currently used cluster, defaulting to doduo")
    cluster = "doduo"
}

params.config_profile_description = 'Configuration profile for execution of Nextflow pipelines on the VSC UGhent HPC.'
params.config_profile_contact = 'ict@cmgg.be'
params.config_profile_url = 'https://www.ugent.be/hpc/en'

switch(cluster) {
    case "skitty":
        params {
            max_memory = 177.GB
            max_cpus = 36
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'skitty'
            resourceLimits = [
                cpus: 36,
                memory: 177.GB,
                time: 72.h
            ]
        }
        break
    case "kirlia":
        params {
            max_memory = 738.GB
            max_cpus = 36
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'kirlia'
            resourceLimits = [
                cpus: 36,
                memory: 738.GB,
                time: 72.h
            ]
        }
        break
    case "doduo":
        params {
            max_memory = 250.GB
            max_cpus = 96
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'doduo'
            resourceLimits = [
                cpus: 96,
                memory: 250.GB,
                time: 72.h
            ]
        }
        break
    case "shinx":
        params {
            max_memory = 360.GB
            max_cpus = 192
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'shinx'
            resourceLimits = [
                cpus: 128,
                memory: 256.GB,
                time: 72.h
            ]
        }
        break
    case "cpu_rome":
        params {
            max_memory = 256.GB
            max_cpus = 128
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'dodrio/cpu_rome'
            clusterOptions = "-A ${tier1_project}"
            resourceLimits = [
                cpus: 128,
                memory: 256.GB,
                time: 72.h
            ]
        }
        break
    case "cpu_rome_512":
        params {
            max_memory = 512.GB
            max_cpus = 128
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'dodrio/cpu_rome_512'
            clusterOptions = "-A ${tier1_project}"
            resourceLimits = [
                cpus: 128,
                memory: 256.GB,
                time: 72.h
            ]
        }
        break
    case "cpu_milan":
        params {
            max_memory = 256.GB
            max_cpus = 128
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'dodrio/cpu_milan'
            clusterOptions = "-A ${tier1_project}"
            resourceLimits = [
                cpus: 128,
                memory: 256.GB,
                time: 72.h
            ]
        }
        break
    case "gpu_rome_a100_40":
        params {
            max_memory = 256.GB
            max_cpus = 48
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'dodrio/gpu_rome_a100_40'
            clusterOptions = "-A ${tier1_project}"
            resourceLimits = [
                cpus: 48,
                memory: 256.GB,
                time: 72.h
            ]
        }
        break
    case "gpu_rome_a100_80":
        params {
            max_memory = 512.GB
            max_cpus = 48
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'dodrio/gpu_rome_a100_80'
            clusterOptions = "-A ${tier1_project}"
            resourceLimits = [
                cpus: 48,
                memory: 512.GB,
                time: 72.h
            ]
        }
        break
    case "debug_rome":
        params {
            max_memory = 256.GB
            max_cpus = 48
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'dodrio/debug_rome'
            clusterOptions = "-A ${tier1_project}"
            resourceLimits = [
                cpus: 48,
                memory: 256.GB,
                time: 72.h
            ]
        }
        break
    case "cpu_rome_all":
        params {
            max_memory = 250.GB
            max_cpus = 128
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'dodrio/cpu_rome_all'
            clusterOptions = "-A ${tier1_project}"
            resourceLimits = [
                cpus: 128,
                memory: 250.GB,
                time: 72.h
            ]
        }
        break
    case "gpu_rome_a100":
        params {
            max_memory = 384.GB
            max_cpus = 48
            max_time = "3day"
        }

        process {
            executor = 'slurm'
            queue = 'dodrio/gpu_rome_a100'
            clusterOptions = "-A ${tier1_project}"
            resourceLimits = [
                cpus: 48,
                memory: 384.GB,
                time: 72.h
            ]
        }
        break
}

// Define profiles for each cluster
profiles {
    skitty {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    kirlia {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    doduo {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    shinx {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    cpu_rome {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    cpu_rome_512 {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    cpu_milan {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    gpu_rome_a100_40 {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    gpu_rome_a100_80 {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    debug_rome {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    cpu_rome_all {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }

    gpu_rome_a100 {
        System.err.println("Using the '-profile vsc_ugent,<cluster>' is deprecated in favor of '-profile vsc_ugent'. The config will now automatically determine the currently used cluster.")
    }
}
