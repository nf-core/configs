/* ----------------------------------------------------
 * Nextflow config file for the LRZ cm4 cluster
 * ----------------------------------------------------
 */

manifest {
    name = 'LRZ CM4 Configuration'
    author = 'Niklas Schandry, Amit Fenn, Frederik Dr√∂st'
    homePage = 'plantmicrobe.de'
    description = 'Configuration for LRZ CM4 cluster'
}

params {
    // Configuration metadata
    config_profile_name = 'LRZ CM4'
    config_profile_description = 'LRZ CM4 configuration'
    config_profile_contact = 'Niklas Schandry(@nschan), Amit Fenn (@amitfenn)'
    config_profile_url = 'https://doku.lrz.de/job-processing-on-the-linux-cluster-10745970.html/'
    config_version = '1.0.0'
    // Default output directory (relative to launch directory)
    outdir = 'results'
}

apptainer {
    enabled = true
    autoMounts = true
}

process {
    executor =
        System.getenv("FLUX_URI") ? // If this is set we are in a flux-in-slurm situation
            'flux' : // Since we only support flux and local approaches, the alternative is local
            'local'

    resourceLimits = [
        cpus:   System.getenv("SLURM_CPUS_ON_NODE") ? // for <1 node, we use slurm and can use this var
                    System.getenv("SLURM_CPUS_ON_NODE").toInteger() :  // for > 1 node, we use flux, the maximum we can allocate to one job 112 CPU
                    112,
        memory: System.getenv("SLURM_CPUS_ON_NODE") ? // if we are in a slurm job, we assume that MEM-per-CPU is 4.5GB
                    (System.getenv("SLURM_CPUS_ON_NODE").toInteger() * 4500.MB) :
                    480.GB // if we are not in a slurm job, we are in a node-spanning flux job, and one job can request up to 480.GB (488GB available per node)
    ]
}

trace {
    enabled = true
    overwrite = true
}

report {
    enabled = true
    overwrite = true
}

timeline {
    enabled = true
    overwrite = true
}

dag {
    enabled = true
    overwrite = true
}
